# Automatic Prompt Generation

## Overview
This repository involves an automatic solution of generating and selecting instructions for prompting LLMs. For example, instead of sending a question to an LLM, an instruction will be generated before the question in order to get the most accurate response by the QA bot. The approach harnesses the ability of LLMs to produce candidate instructions, which are then ranked using a
scoring model to determine the most effective prompts.The repository is based on the original notebook by Matt Shumer, https://github.com/mshumer/gpt-prompt-engineer. 

First, you need to ask an Anthropic Claude model to generate an instruction for a set of inputs
(question and context) as well as an output (answer). The LLM is then asked to generate a
specific type of instruction, such as a one-paragraph instruction, one-sentence instruction, or
step-by-step instruction. 10 such candidate instructions are generated from this LLM.

Then, the resulting 10 instructions are tested against each other using an evaluation LLM (a
Claude Instant model). To do this, first, each instruction is
compared against all other instructions. Then, the evaluation LLM is used to evaluate the
quality of prompts for a given task (query and context to answer pairs).

This outputs the most ideal prompt generated by the framework. For each question-answer
pair, the outputs include the best instruction, second best instruction, and third best
instruction. 

## Steps to Run AutoPrompt
1. Run ```pip install -r requirements.txt```

2. Make sure to edit the configs file in src/utils.configs.py, primarily the absolute path variables. 

3. Make sure you run your dataset with Ragas. Upload your dataset (update ragas_output.csv with your dataset) in the data folder. Instructions for how to run Ragas is in the 'Prompt_Engineer_Ragas.ipynb' notebook. 

4. Go through notebook 'notebooks/Prompt_Engineer_Ragas.ipynb'. Included in the notebook is a section on how to evaluate a dataset using Ragas. These outputs are inputted into the autoPrompt algorithm. The results from the notebook are uploaded in the data folder. 

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.

