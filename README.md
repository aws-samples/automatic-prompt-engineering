# Automatic Prompt Generation

## Overview
This repository involves an automatic solution of generating and selecting instructions for prompting LLMs. For example, instead of sending a question to an LLM, an instruction will be generated before the question in order to get the most accurate response by the QA bot. The approach harnesses the ability of LLMs to produce candidate instructions, which are then ranked using a
scoring model to determine the most effective prompts.The repository is based on the original notebook by Matt Shumer, https://github.com/mshumer/gpt-prompt-engineer. 

First, you need to ask an Anthropic Claude model to generate an instruction for a set of inputs
(question and context) as well as an output (answer). The LLM is then asked to generate a
specific type of instruction, such as a one-paragraph instruction, one-sentence instruction, or
step-by-step instruction. N such candidate instructions are generated from this LLM.

Then, the resulting N instructions are tested against each other using an evaluation LLM (a
Claude Instant model). To do this, first, each instruction is
compared against all other instructions. Then, the evaluation LLM is used to evaluate the
quality of prompts for a given task (query and context to answer pairs).

This outputs the most ideal prompt generated by the framework. For each question-answer
pair, the outputs include the best instruction, second best instruction, and third best
instruction. 

The dataset provided in this repository comes from the python datasets library from "explodinggradients/amnesty_qa": "english_v2". This dataset is 
run on Ragas (as shown in the example notebook). 

## Steps to Run AutoPrompt
1. Run ```pip install -r requirements.txt```

2. Make sure to edit the configs file in src/utils.configs.py, primarily the absolute path variables. You can also change the NUMBER_OF_PROMPTS (the value for N candidate instructions generated), the model types to either Claude Instant, Claude v2, or Claude 3 Haiku (you can test and modify the code where fit to use other Bedrock hosted foundational models), and the prompts. The system_gen_prompt includes descriptions and test_cases that are available in the instruction_generation_templates/ folder. 

3. Make sure you run your dataset with Ragas. Upload your dataset and make sure it is in a similar format as shown in notebooks/Prompt_Engineer_Ragas.ipynb in the 'Import Sample Dataset' section. Instructions for how to run Ragas is in that same notebook. 

4. Go through notebook 'notebooks/Prompt_Engineer_Ragas.ipynb'. Included in the notebook is a section on how to evaluate a dataset using Ragas. These outputs are inputted into the autoPrompt algorithm. The results from the notebook are uploaded in the data folder. 

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.

